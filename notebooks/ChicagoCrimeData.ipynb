{"nbformat_minor": 2, "cells": [{"execution_count": 1, "cell_type": "code", "source": "from pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import HashingTF, Tokenizer\nfrom pyspark.sql import Row\nfrom pyspark.sql.functions import UserDefinedFunction, col\nfrom pyspark.sql.types import *\nfrom functools import reduce\nimport matplotlib.pyplot as plt", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Starting Spark application\n"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>4</td><td>application_1520184071391_0008</td><td>pyspark3</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn1-huffer.ig0chmy2iqbe3ovkyytbq42rqf.gx.internal.cloudapp.net:8088/proxy/application_1520184071391_0008/\">Link</a></td><td><a target=\"_blank\" href=\"http://wn1-huffer.ig0chmy2iqbe3ovkyytbq42rqf.gx.internal.cloudapp.net:30060/node/containerlogs/container_1520184071391_0008_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": "SparkSession available as 'spark'.\n"}], "metadata": {"collapsed": false}}, {"execution_count": 2, "cell_type": "code", "source": "crime_one = spark.read.csv(\"wasb:///ChicagoCrimeData/Chicago_Crimes_2001_to_2004.csv\", header=True, inferSchema=True)\ncrime_two = spark.read.csv(\"wasb:///ChicagoCrimeData/Chicago_Crimes_2005_to_2007.csv\", header=True, inferSchema=True)\ncrime_three = spark.read.csv(\"wasb:///ChicagoCrimeData/Chicago_Crimes_2008_to_2011.csv\", header=True, inferSchema=True)\ncrime_four = spark.read.csv(\"wasb:///ChicagoCrimeData/Chicago_Crimes_2012_to_2017.csv\", header=True, inferSchema=True)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "crime_one.printSchema();", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "crime_two.printSchema();", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "crime_three.printSchema();", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "crime_four.printSchema();", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 3, "cell_type": "code", "source": "crime_schema = {field.name:field.dataType for field in crime_two.schema.fields}\ncrime_one_cols = crime_one.columns\n\nfor i in crime_one_cols:\n    crime_one = crime_one.withColumn(i, crime_one[i].cast(crime_schema[i]))\n    \nChicagoCrime = crime_one.union(crime_two).union(crime_three).union(crime_four)\n\nOldColumnNames = ChicagoCrime.columns\nNewColumnNames = ['_c0', 'ID', 'CaseNumber', 'Date', 'Block', 'IUCR', 'PrimaryType', 'Description', 'LocationDescription', 'Arrest', 'Domestic', 'Beat', 'District', 'Ward', 'CommunityArea', 'FBICode', 'XCoordinate', 'YCoordinate', 'Year', 'UpdatedOn', 'Latitude', 'Longitude', 'Location']\nChicagoCrime = reduce(lambda ChicagoCrime, idx: ChicagoCrime.withColumnRenamed(OldColumnNames[idx], NewColumnNames[idx]), range(len(OldColumnNames)), ChicagoCrime)\n\nChicagoCrime_Cols = ['ID', 'CaseNumber', 'Date', 'Block', 'IUCR', 'PrimaryType', 'Description', 'LocationDescription', 'Arrest', 'Domestic', 'Beat', 'District', 'Ward', 'CommunityArea', 'FBICode', 'Year', 'UpdatedOn']\nChicagoCrime = ChicagoCrime.select(ChicagoCrime_Cols)\nChicagoCrime.printSchema()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "root\n |-- ID: integer (nullable = true)\n |-- CaseNumber: string (nullable = true)\n |-- Date: string (nullable = true)\n |-- Block: string (nullable = true)\n |-- IUCR: string (nullable = true)\n |-- PrimaryType: string (nullable = true)\n |-- Description: string (nullable = true)\n |-- LocationDescription: string (nullable = true)\n |-- Arrest: boolean (nullable = true)\n |-- Domestic: boolean (nullable = true)\n |-- Beat: integer (nullable = true)\n |-- District: double (nullable = true)\n |-- Ward: double (nullable = true)\n |-- CommunityArea: double (nullable = true)\n |-- FBICode: string (nullable = true)\n |-- Year: integer (nullable = true)\n |-- UpdatedOn: string (nullable = true)"}], "metadata": {"collapsed": false}}, {"execution_count": 4, "cell_type": "code", "source": "ChicagoCrime.fillna('Missing Data', ChicagoCrime_Cols)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "DataFrame[ID: int, CaseNumber: string, Date: string, Block: string, IUCR: string, PrimaryType: string, Description: string, LocationDescription: string, Arrest: boolean, Domestic: boolean, Beat: int, District: double, Ward: double, CommunityArea: double, FBICode: string, Year: int, UpdatedOn: string]"}], "metadata": {"collapsed": false}}, {"execution_count": 5, "cell_type": "code", "source": "ChicagoCrime.registerTempTable(\"ChicagoCrime\")", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "%%sql\nSELECT *\nFROM ChicagoCrime\nLIMIT 10", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "%%sql\nSELECT DISTINCT(PrimaryType)\nFROM ChicagoCrime", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 6, "cell_type": "code", "source": "# Use this to create new data frame based on out from query\nChicagoCrimeLabeled = sqlContext.sql(\n\"SELECT ID ,CaseNumber ,Date ,Block ,IUCR, PrimaryType ,Description ,LocationDescription ,Arrest ,Domestic ,Beat ,District ,Ward \"\n+ \",CommunityArea ,FBICode ,Year ,UpdatedOn \"\n+ \",CASE \"\n+ \"WHEN PrimaryType IN ('OFFENSE INVOLVING CHILDREN', 'ARSON', 'DOMESTIC VIOLENCE', 'ASSAULT', 'ROBBERY', 'HOMICIDE', 'CRIM SEXUAL ASSAULT', 'SEX OFFENSE', 'BURGLARY') \"\n+ \"THEN 'SERIOUS CRIME' \"\n+ \"ELSE 'NON-SERIOUS CRIME' \"\n+ \"END AS SeriousCrime \"\n+ \",CASE \"\n+ \"WHEN PrimaryType IN ('OFFENSE INVOLVING CHILDREN', 'ARSON', 'DOMESTIC VIOLENCE', 'ASSAULT', 'ROBBERY', 'HOMICIDE', 'CRIM SEXUAL ASSAULT', 'SEX OFFENSE', 'BURGLARY')\"\n+ \"THEN 1 \"\n+ \"ELSE 0 \"\n+ \"END AS SeriousCrimeIndicator \"\n+ \"FROM ChicagoCrime\"\n)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 8, "cell_type": "code", "source": "ChicagoCrimeLabeled.printSchema()", "outputs": [{"output_type": "stream", "name": "stderr", "text": "An error was encountered:\nSession 4 unexpectedly reached final status 'error'. See logs:\n\n"}], "metadata": {"collapsed": false}}, {"source": "## Ignore the lines below: Error occurs when trying to execute the model fitting.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "%%local\n%matplotlib inline\n\nlabels = ChicagoCrimeCount['SeriousCrimeIndicator']\nsizes = ChicagoCrimeCount['SeriousCrimeCount']\ncolors = ['red', 'blue']\nplt.pie(sizes, labels = labels, autopct='%1.1f%%', colors = colors)\nplt.axis('equal')", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "def labelForResults(s):\n    if s == 'OFFENSE INVOLVING CHILDREN' or s == 'ARSON' or s == 'DOMESTIC VIOLENCE' or s == 'ASSAULT' or s == 'ROBBERY' or s == 'HOMICIDE' or s == 'CRIM SEXUAL ASSAULT' or s == 'SEX OFFENSE' or s == 'BURGLARY':\n        return 1.0\n    else:\n        return 0.0\nlabel = UserDefinedFunction(labelForResults, DoubleType())\nlabeledData = ChicagoCrime.select(label(ChicagoCrime.PrimaryType).alias('label'), ChicagoCrime.LocationDescription).where('label >= 0')", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "labeledData.take(1)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "tokenizer = Tokenizer(inputCol=\"LocationDescription\", outputCol=\"words\")\nhashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\nlr = LogisticRegression(maxIter=10, regParam=0.01)\npipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n\nmodel = pipeline.fit(labeledData)\nmodel", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark3", "name": "pyspark3kernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python3", "name": "pyspark3", "codemirror_mode": {"version": 3, "name": "python"}}}}